{
    "metadata": {
        "kernelspec": {
            "name": "SQL",
            "display_name": "SQL",
            "language": "sql"
        },
        "language_info": {
            "name": "sql",
            "version": ""
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": "<img src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/solutions-microsoft-logo-small.png?raw=true\" alt=\"Microsoft\">\r\n<br>\r\n\r\n# Workshop: Microsoft SQL Server Machine Learning Services\r\n\r\n#### <i>A Microsoft Course from the SQL Server team</i>\r\n\r\n## 05 - Phase 3: Modeling\r\n\r\n<p style=\"border-bottom: 1px solid lightgrey;\"></p>\r\n\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/textbubble.png?raw=true\"></p>\r\n\r\n<br>\r\n<br>\r\n<br>\r\n\r\nYou're learning to use the Team Data Science Process to create a complete solution, using SQL Server as the platform. The phases in the Team Data Science process are:\r\n\r\n<dl>\r\n  <dt>1 - Business Understanding</dt>\r\n  <dt>2 - Data Acquisition and Understanding</dt>\r\n  <dt>3 - Modeling <i>(This module)</i></dt>\r\n  <dt>4 - Deployment</dt>\r\n  <dt>5 - Customer Acceptance and Model Retraining</dt>\r\n<dl>\r\n\r\n<p style=\"border-bottom: 1px solid lightgrey;\"></p>\r\n\r\n<img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/pin.jpg?raw=true\">\r\n<br>\r\n\r\nIn this phase, you'll perform feature engineering, create the experiment runs, and run experiments with various settings and parameters. After selecting the best performing run, you'll create a trained model and save it for operationalization in the next phase.\r\n\r\n### Goals for Modeling\r\n\r\n- Determine the optimal data features for the machine-learning model.\r\n- Create an informative machine-learning model that predicts the target most accurately.\r\n- Create a machine-learning model that's suitable for production.\r\n\r\n### How to do it\r\n\r\n- Feature engineering: Create data features from the raw data to facilitate model training.\r\n- Model training: Find the model that answers the question most accurately by comparing their success metrics.\r\n- Determine if your model is suitable for production.\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/pin.jpg?raw=true\"><b>4.1 Data Engineering</b></p>\r\n\r\nOften times, the data needs to be prepared and cleaned before you start training the Model. In this course, most of the preparations have already been done within the database, but to work with the data you have to create this model, you'll convert certain values to factors, making them categorical, creating rolling windows for the maintenance and other tasks.\r\n\r\nYou'll use a Jupyter Notebook environment to work with your model. You're doing that for this course as a learning exercise, although this is a common way of working with a Data Science project. It's also common to work with Azure Machine Learning Services, Azure DataBricks, Azure Cosmos DB or other tools to explore your data, create an experiment, and create and train a model.\r\n\r\nThe key to the Hybrid Machine Learning Scenario is that you create that model in one location, store the results as a serialized model (using Python's \"Pickle\" function or the ONNX standard, and then bring that model in to a local environment using an engine like SQL Server ML Services or [ML.NET with ONNX](https://blogs.msdn.microsoft.com/dotnet/2018/10/08/announcing-ml-net-0-6-machine-learning-net/) to do the predictions.\r\n\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/checkbox.png?raw=true\"><b>Activity: Feature Engineering using Python</b></p>\r\n\r\n**NOTE:** *Allow each Cell to complete before continuing on to a new Cell - running the next Cell before the previous one finish will cause your experiment to fail.*\r\n\r\n- Continue (or re-connect) to the course's Jupyter Notebook.\r\n- One inside the Notebook, look for the section marked `04 Modeling`, and then the section below that marked `Activity: Feature Engineering using Python`.\r\n- Read the Cell instructions, and then click `Run` to process the data into Features. Note that this will take some time. *(Whenever the Kernel is working on a task, the small circe next to the words `HybridML` in the top right corner of the Notebook will be filled in)*\r\n\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/pin.jpg?raw=true\"><b>4.2 Train the Model</b></p>\r\n\r\nIn order to predict using a Model, you have to first find a function that best describes the dependency between the variables in your dataset. This step is called *training the model*. The training dataset will be a subset of the entire dataset. In the next exercise you are going to create the model using the Features and Labels from the previous exercise.\r\n\r\nIn production, you will use multiple algorithms and variables (hyperparameters) to find the best model. In this case, you'll focus on one model, and use that. You will, however, see how to evaluate the model, which you would do with each run (experiment).\r\n\r\nYou'll use one set of data to train your model, and another other to test how well it performed. In this activity you will use a natural time-period-break (rolling window) to segment the testing and training data. This is a process you should repeat with different ways of separating this data, since one parameter or another might have factors that unduly weight the results.\r\n\r\nIt's interesting to see that the Data Scientist decided to use the Pandas function of the Rolling Mean. This function is now deprecated in Pandas. You have two choices - you can create the same environment that the original developer used (*as we have had you do in this course*) or you could fix the code. Fixing the code means changing - however slightly - the original experiment. This course had you duplicate the original environment, which took quite a bit of tuning to get right - recall all the conda statements you ran to get the environment correct. This is a real-world lesson on working with multiple people in a team project.\r\n\r\n*As a \"stretch\" assignment, you can go back after you complete the course and attempt to re-create the code with the correct syntax. Of course, this means that you will then have to ensure that the Operationalizing system (SQL Server ML Services in this case) **also** has the right code/library version combination.*\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/checkbox.png?raw=true\"><b>Activity: Create the Training Experiment</b></p>\r\n\r\n- Continue (or re-connect) to the course's Jupyter Notebook.\r\n- One inside the Notebook, look for the section marked `04 Modeling`, and then the section below that marked `Activity: Create the Training Experiment`.\r\n- Read the Cell instructions, and then click `Run` to process the data into Features in each Cell. Note that this will take some time. *(Whenever the Kernel is working on a task, the small circe next to the words `HybridML` in the top right corner of the Notebook will be filled in)*\r\n- Remember to wait for each cell to complete.\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/pin.jpg?raw=true\"><b>4.3 Evaluating the Model</b></p>\r\n\r\nFor each type of algorithm and each set of hyperparameters you choose, you should evaluate the performance of the results. You can do that by working with various Machine Learning concepts such as a confusion matrix, an FI-score, and more.",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/checkbox.png?raw=true\"><b>Activity: Evaluating Training Performance</b></p>\r\n\r\nYou'll use your Jupyter Notebook to work with Azure ML Services. While the experiment runs, take a look at the next section, *4.4 Using Azure ML Services*.\r\n\r\n**NOTE:** *Allow each Cell to complete before continuing on to a new Cell - running the next Cell before the previous one finish will cause your experiment to fail.*\r\n\r\n- Continue (or re-connect) to the course's Jupyter Notebook in your DSVM.\r\n- One inside the Notebook, look for the section marked `04 Modeling`, and then the section below that marked `Activity: Evaluating Training Performance`.\r\n- Read the Cell instructions, and then click `Run` to process the data into Features in each Cell. Note that this will take some time. *(Whenever the Kernel is working on a task, the small circe next to the words `HybridML` in the top right corner of the Notebook will be filled in)*\r\n- Stop at the cell marked `Evaluation`.\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/pin.jpg?raw=true\"><b>4.4 Using Azure ML Services</b></p>\r\n\r\nUsing Azure ML Services to create these experiments allows greater scale, and many service-based features that allow you to create, run, and manage the entire process. Azure ML Services also helps a great deal with the environment and CI/CD aspects of your work.\r\n\r\nYou spent some time on these decisions during the Architecture Design Session, and there are a few other components that will assist in your model development:\r\n\r\n- [Azure ML Service](https://docs.microsoft.com/en-us/azure/machine-learning/service/overview-what-is-azure-ml) - Develop and deploy machine learning models at scale.\r\n- [Azure ML SDK](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py) - Build and run machine learning workflows upon the Azure Machine Learning service. [Short video on this process is here](https://channel9.msdn.com/Shows/AI-Show/VS-Code-Tools-for-AI-Train-ML-Models-With-Azure-Machine-Learning)\r\n- [Azure AutoML](https://docs.microsoft.com/en-gb/azure/machine-learning/service/tutorial-auto-train-models) - Identify the best algorithm to use for a given Machine Learning Problem. [More here](https://azure.microsoft.com/en-us/blog/announcing-automated-ml-capability-in-azure-machine-learning/)\r\n- [Azure Hyperdrive](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters) -  Automatically tune hyperparameters for your model using Azure Machine Learning service.\r\n- [ONNX](https://onnx.ai/) - An open format to represent deep learning models, allows transfer between frameworks (such as TensorFlow and PyTorch)\r\n- [Azure DevOps](https://azure.microsoft.com/en-us/solutions/devops/) - Automate the entire process from code commit to production if your CI/CD tests are successful.\r\n\r\nYour instructor will show you the general thoughts around these areas, and then you'll incorporate these features into the design.\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/checkbox.png?raw=true\"><b>Activity: Incorporate Azure ML Services into the Solution</b></p>\r\n\r\n- Using the information above, examine the architecture for where it fits. What changes could/should you make to take advantage of these services?\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/thinking.jpg?raw=true\"><b>For Further Study</b></p>\r\n\r\n<br>\r\n<br>\r\n\r\n - Learn more about Feature Engineering and Modeling here: https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/lifecycle-modeling\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/education1.png?raw=true\"><b>Next</b>: Phase 4 - Deployment</p>\r\n\r\nNext, you'll start working through the Team Data Science Process in the next phase - Deployment. Open that Notebook to continue.",
            "metadata": {}
        }
    ]
}